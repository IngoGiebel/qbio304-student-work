# Notes:
# This script is organized into 'chunks' of code, and the final chunk (called
# 'the essentials') is a minimal representation of this script.

# Load packages-----------------------------------------------------------------

# BiocManager::install("BSgenome.Osativa.MSU.MSU7")
# BiocManager::install("clusterProfiler")
# BiocManager::install("GSVA")
# BiocManager::install("qusage")

# Provides static code analysis for R. It checks for adherence to a given style,
# identifying syntax errors and possible semantic issues.
library(lintr)
# For accoustic feedback when a step is finished
library(beepr)
# Tools for Data Copy-Pasta. RStudio addins and R functions that make
# copy-pasting vectors and tables to text painless.
library(datapasta)
# Hadley Wickham's collection of R packages for data science
library(tidyverse)
# To transform data between wide and long formats
library(reshape2)
# let's us easily calculate stats on rows or columns of a data matrix
library(matrixStats)
# To combine multiple plots in one figure
library(cowplot)
# For making interactive plots
library(plotly)
# For plotting heatmaps
library(gplots)
# For making interactive tables
library(DT)
# A layered 'grammar of tables' - think ggplot2, but for tables
library(gt)
# For creating interactive cluster heatmaps
library(heatmaply)
# Access the Bioconductor Project Package Repository. A convenient tool to
# install and update Bioconductor packages.
library(BiocManager)
# For using ensembldb annotation packages
library(ensembldb)
# An alternative for annotation
library(biomaRt)
# Package for getting Kallisto results into R
library(tximport)
# Provides functions for handling hdf5 file formats (kallisto outputs bootstraps
# in this format)
library(rhdf5)
# For differential expression analysis. Here used for the DGEList object
# and for data normalization.
library(edgeR)
# To analyze changes in genome-wide patterns of alternative splicing and its
# functional consequences
library(IsoformSwitchAnalyzeR)
# Provides functions and methods for Gene Set Enrichment Analysis
library(GSEABase)
# For Gene Set Variation Analysis, a non-parametric and unsupervised method for
# estimating variation of gene set enrichment across samples.
library(GSVA)
# Provides tools for accessing the GO enrichment results using g:Profiler
# web resources
library(gprofiler2)
# Provides a suite of tools for functional enrichment analysis
library(clusterProfiler)
# Provides access to msigdb collections directly within R
library(msigdbr)
# For making the standard GSEA enrichment plots
library(enrichplot)
# Quantitative Set Analysis for Gene Expression
library(qusage)

# Replace with your organism-specific database package
# TODO: remove
library(EnsDb.Hsapiens.v86)
# Oryza sativa specific database
# BiocManager::install("BSgenome.Osativa.MSU.MSU7")
library(BSgenome)


# Step 1------------------------------------------------------------------------

# Learning Objectives:
# 1 - Step 1 serves as your gateway to R scripts and, as such, you will learn
#     the proper 'anatomy' for any R script.
# 2 - Learn how to install packages and load libraries into your R environment.
# 3 - Understand the various file types that describe RNAseq data and how to
#     import these files (e.g. kallisto read mapping data) into R
# 4 - Learn basic tools for annotation

# Read in the study design file
targets <- readr::read_tsv("studydesign.txt")

# you can easily create file paths to the abundance files generated by Kallisto
# using the 'file.path' function
# set file paths to your mapped data
path <- file.path(targets$sra_accession, "abundance.tsv")
# now check to make sure this path is correct by seeing if the files exist
# The functions which(), any() and all() take logical vectors as their argument.
# The any() function will return TRUE if one or more of the elements in the
# logical vector is TRUE. The all() function will return TRUE if every element
# in the logical vector is TRUE.
all(file.exists(path))


# Get annotations using organism-specific package ------------------------------
# TODO replace
Tx <- ensembldb::transcripts(
  EnsDb.Hsapiens.v86,
  columns = c("tx_id", "gene_name")
)
Tx <- tibble::as_tibble(Tx)
# Need to change first column name to 'target_id'
Tx <- dplyr::rename(Tx, target_id = "tx_id")
# Transcript ID needs to be the first column in the dataframe
Tx <- dplyr::select(Tx, "target_id", "gene_name")


# OPTIONAL: get annotations using BiomaRt---------------------------------------

# The annotation method described in the code chunk above works great if an
# organism-specific data base package exists for your organisms of interest.
# However, this is only the case for human, mouse and rat....
# So, this optional code chunk shows one way you can get annotation data for
# other target organisms in this example, we're retrieving 1:1 mappings between
# transcript identifiers and gene symbols for tomato

# Default host is ensembl.org, and most current release of mammalian genomes
biomaRt::listMarts()
# access to parasite worm genomes:
# listMarts(host = "https://parasite.wormbase.org")
# access to protozoan genomes:
# listMarts(host = "https://protists.ensembl.org")
# access to plant genomes:
biomaRt::listMarts(host = "https://plants.ensembl.org")

# choose the 'mart' you want to work with
# marts for mammalian genomes:
# myMart <- useMart(biomart="ENSEMBL_MART_ENSEMBL")
# marts for plant genomes:
myMart <- biomaRt::useMart(
  biomart = "plants_mart",
  host = "https://plants.ensembl.org",
  verbose = TRUE)
# take a look at all available datasets within the selected mart
available.datasets <- biomaRt::listDatasets(myMart)

# TODO replace:
# Oryza nivara               : onivara_eg_gene
# Oryza sativa Japonica Group: osativa_eg_gene
# Ensembl annotations for tomato
lyc.anno <- useMart(
  biomart = "plants_mart",
  dataset = "slycopersicum_eg_gene",
  host = "https://plants.ensembl.org")
lyc.attributes <- listAttributes(lyc.anno)
# take a look at all available attributes within the selected tomato annotation
Tx.lyc <- getBM(
  attributes = c("ensembl_transcript_id", "ensembl_gene_id", "description"),
  mart = lyc.anno)
# turn it into a tibble
Tx.lyc <- tibble::as_tibble(Tx.lyc)
# we need to rename the two columns we just retreived from biomart
Tx.lyc <- dplyr::rename(
  Tx.lyc,
  target_id = "ensembl_transcript_id",
  gene_name = "ensembl_gene_id")
Tx.lyc <- dplyr::select(Tx.lyc, "target_id", "gene_name")

# import Kallisto transcript counts into R using Tximport ----
# copy the abundance files to the working directory and rename so that each
# sample has a unique name
# TODO mapping tx2gene = Tx
# Default: ***gene-level summarization (txOut = FALSE)***.
# Setting txOut = TRUE gives the original transcript level estimates as a
# list of matrices.
# See https://bioconductor.org/packages/devel/bioc/vignettes/tximport/inst/doc/tximport.html
Txi_gene <- tximport::tximport(
  path,
  type = "kallisto",
  # Mapping from transcript IDs to gene IDs
  tx2gene = Tx,
  countsFromAbundance = "lengthScaledTPM",
  ignoreTxVersion = TRUE)

# TODO remove (not needed anymore)
Txi_trans <- tximport::tximport(
  path,
  type = "kallisto",
  # Mapping from transcript IDs to gene IDs
  tx2gene = Tx,
  # How does the result change if this =FALSE vs =TRUE?
  txOut = TRUE,
  countsFromAbundance = "lengthScaledTPM",
  ignoreTxVersion = TRUE)

beep(sound = 1)

# Take a look at the type of object you just created
class(Txi_gene)
names(Txi_gene)

print("Step 1 complete!")


# Step 1: the essentials -------------------------------------------------------

# This chunk contains the minimal essential code from this script

library(tidyverse)
# package for getting Kallisto results into R
library(tximport)
# helps deal with ensembl
library(ensembldb)
#replace with your organism-specific database package
library(EnsDb.Hsapiens.v86)

# read in your study design
targets <- readr::read_tsv("studydesign.txt")
# set file paths to your mapped data
path <- file.path(targets$sra_accession, "abundance.tsv")
Tx <- tibble::as_tibble(
  transcripts(
    EnsDb.Hsapiens.v86,
    columns = c("tx_id", "gene_name"))
  )
Tx <- dplyr::rename(Tx, target_id = "tx_id")
Tx <- dplyr::select(Tx, "target_id", "gene_name")
Txi_gene <- tximport::tximport(
  path,
  type = "kallisto",
  tx2gene = Tx,
  # Determines whether your data represented at transcript or gene level
  txOut = FALSE,
  countsFromAbundance = "lengthScaledTPM",
  ignoreTxVersion = TRUE)


# Step 2------------------------------------------------------------------------

# Now that you've read your transcript-level or gene-level data into R,
# you're ready to begin working with your data.

# Step 2 Objectives:
# 1 - Filter and normalize your data.
# 2 - use ggplot2 to visualize the impact of filtering and normalization
#     on our data.
# 3 - understand why gene expression data is messy, and how to make it 'tidy'.

# Notes:
# recall that your abundance data are TPM (transcript per million), while th
# counts are read counts mapping to each gene or transcript

# Examine your data up to this point ----
myTPM <- Txi_gene$abundance
myCounts <- Txi_gene$counts
colSums(myTPM)
colSums(myCounts)

# capture sample labels from the study design file that you worked with and
# saved as 'targets' in step 1
targets
sampleLabels <- targets$sample

# Generate summary stats for your data ----
# 1st, calculate summary stats for each transcript or gene, and add these
# to your data matrix.
# then use the base R function 'transform' to modify the data matrix.
# then we use the 'rowSds', 'rowMeans' and 'rowMedians' functions from
# the matrixStats package
# TODO: use the tidyverse transform function.
# TODO: use pipes.
myTPM.stats <- transform(
  myTPM,
  SD = matrixStats::rowSds(myTPM),
  AVG = rowMeans(myTPM),
  MED = matrixStats::rowMedians(myTPM))

# look at what you created
head(myTPM.stats)

# Create your first plot using ggplot2 ----
# produce a scatter plot of the transformed data
ggplot2::ggplot(myTPM.stats) +
  aes(x = SD, y = MED) +
  geom_point(shape = 1, size = 3)
# Experiment with point shape and size in the plot above
# Experiment with other plot types (e.g. 'geom_hex' instead of 'geom_point')
# Add a theme to your ggplot code above.  Try 'theme_bw()'
# How would these graphs change if you log2 converted the data?

# Let's expand on the plot above a bit more and take a look at each 'layer'
# of the ggplot code
ggplot2::ggplot(myTPM.stats) +
  aes(x = SD, y = MED) +
  geom_point(shape = 1, size = 2) +
  geom_smooth(method = lm) +
  geom_hex(show.legend = T, bins = 20) +
  labs(
    y = "Median",
    x = "Standard deviation",
    title = "Transcripts per million (TPM)",
    subtitle = "unfiltered, non-normalized data",
    caption = "DIYtranscriptomics - Spring 2020") +
  theme_bw()

# Make a DGElist from your counts, and plot ----
myDGEList <- edgeR::DGEList(myCounts)
# take a look at the DGEList object
myDGEList
# DEGList objects are a good R data file to consider saving to you
# working directory
save(myDGEList, file = "myDGEList")
# Saved DGEList objects can be easily shared and loaded into an R environment
load(file = "myDGEList")

# use the 'cpm' function from EdgeR to get counts per million
cpm <- edgeR::cpm(myDGEList)
colSums(cpm)
log2.cpm <- edgeR::cpm(myDGEList, log = TRUE)
# 'coerce' your data matrix to a dataframe so that you can use tidyverse tools
# on it
log2.cpm.df <- tibble::as_tibble(log2.cpm, rownames = "geneID")
log2.cpm.df
# add your sample names to this dataframe (we lost these when we read our data
# in with tximport)
colnames(log2.cpm.df) <- c("geneID", sampleLabels)

# use the tidy package to 'pivot' your dataframe (from wide to long)
log2.cpm.df.pivot <- tidyr::pivot_longer(
  log2.cpm.df, # dataframe to be pivoted
  cols = HS01:CL13, # column names to be stored as a SINGLE variable
  names_to = "samples", # name of that new variable (column)
  values_to = "expression") # name of new variable (column) storing all the values (data)

# let's look at the impact of pivoting the data
log2.cpm.df.pivot

# now it is easy to plot this pivoted data
plot1 <- ggplot2::ggplot(log2.cpm.df.pivot) +
  ggplot2::aes(x = samples, y = expression, fill = samples) +
  ggplot2::geom_violin(trim = FALSE, show.legend = FALSE) +
  ggplot2::stat_summary(
    fun = "median",
    geom = "point",
    shape = 95,
    size = 10,
    color = "black",
    show.legend = FALSE) +
  ggplot2::labs(
    y = "log2 expression",
    x = "sample",
    title = "Log2 Counts per Million (CPM)",
    subtitle = "unfiltered, non-normalized",
    caption = paste0("produced on ", Sys.time())) +
  ggplot2::theme_bw()
plot1

# Filter your data ----
# First, take a look at how many genes or transcripts have no read counts at all
table(rowSums(myDGEList$counts == 0) == 10)

# breaking down the line above is a little tricky.  Let's try:
# 1st - 'myDGEList$counts==0' returns a new 'logical matrix' where each
# observation (gene) is evaluated (TRUE/FALSE) for each variable (sample)
# as to whether it has zero counts
# 2nd - passing this logical matrix to 'rowsums' allows you to sum the total
# number of times an observation was 'TRUE' across all samples
# 3rd - adding the '==10' is a simple way of asking how many of the rowsums
# equaled 10. In other words, how many genes had 0 counts (TRUE)
# for all samples in our dataset
# 4th - passing all this to the 'table' function just provides a handy way
# to summarize the large logical produced in the previous step

# now set some cut-off to get rid of genes/transcripts with low counts
# again using rowSums to tally up the 'TRUE' results of a simple evaluation
# how many genes had more than 1 CPM (TRUE) in at least 3 samples

# The line below is important! This is where the filtering starts
# Be sure to adjust this cutoff for the number of samples in the smallest
# group of comparison.
keepers <- rowSums(cpm > 1) >= 5
# now use base R's simple subsetting method to filter your DGEList based on the
# logical produced above
myDGEList.filtered <- myDGEList[keepers,]
dim(myDGEList)
dim(myDGEList.filtered)

log2.cpm.filtered <- edgeR::cpm(myDGEList.filtered, log = TRUE)
log2.cpm.filtered.df <- tibble::as_tibble(
  log2.cpm.filtered,
  rownames = "geneID")
colnames(log2.cpm.filtered.df) <- c("geneID", sampleLabels)
# pivot this FILTERED data, just as you did earlier
log2.cpm.filtered.df.pivot <- tidyr::pivot_longer(
  log2.cpm.filtered.df, # dataframe to be pivoted
  cols = HS01:CL13, # column names to be stored as a SINGLE variable
  names_to = "samples", # name of that new variable (column)
  values_to = "expression") # name of new variable (column) storing all the values (data)

plot2 <- ggplot2::ggplot(log2.cpm.filtered.df.pivot) +
  ggplot2::aes(x = samples, y = expression, fill = samples) +
  ggplot2::geom_violin(trim = FALSE, show.legend = FALSE) +
  ggplot2::stat_summary(
    fun = "median",
    geom = "point",
    shape = 95,
    size = 10,
    color = "black",
    show.legend = FALSE) +
  ggplot2::labs(
    y = "log2 expression",
    x = "sample",
    title = "Log2 Counts per Million (CPM)",
    subtitle = "filtered, non-normalized",
    caption = paste0("produced on ", Sys.time())) +
  ggplot2::theme_bw()
plot2

# Normalize your data ----
myDGEList.filtered.norm <- edgeR::calcNormFactors(
  myDGEList.filtered,
  method = "TMM")
# take a look at this new DGEList object...how has it changed?

# use the 'cpm' function from EdgeR to get counts per million from your
# normalized data
log2.cpm.filtered.norm <- edgeR::cpm(myDGEList.filtered.norm, log = TRUE)
log2.cpm.filtered.norm.df <- tibble::as_tibble(
  log2.cpm.filtered.norm,
  rownames = "geneID")
colnames(log2.cpm.filtered.norm.df) <- c("geneID", sampleLabels)
# pivot this NORMALIZED data, just as you did earlier
log2.cpm.filtered.norm.df.pivot <- tidyr::pivot_longer(
  log2.cpm.filtered.norm.df, # dataframe to be pivoted
  cols = HS01:CL13, # column names to be stored as a SINGLE variable
  names_to = "samples", # name of that new variable (column)
  values_to = "expression") # name of new variable (column) storing all the values (data)

# each ggplot can be saved as an object! (p1, p2, p3)
plot3 <- ggplot2::ggplot(log2.cpm.filtered.norm.df.pivot) +
  ggplot2::aes(x = samples, y = expression, fill = samples) +
  ggplot2::geom_violin(trim = FALSE, show.legend = FALSE) +
  ggplot2::stat_summary(
    fun = "median",
    geom = "point",
    shape = 95,
    size = 10,
    color = "black",
    show.legend = FALSE) +
  ggplot2::labs(
    y = "log2 expression",
    x = "sample",
    title = "Log2 Counts per Million (CPM)",
    subtitle = "filtered, TMM normalized",
    caption = paste0("produced on ", Sys.time())) +
  ggplot2::theme_bw()
plot3

# what if we wanted to put all three violin plots together?
# go back and assign each plot to a variable (rather than printing to the
# plots viewer)
# here we assigned the last 3 plots to p1, p2 and p3
# we'll use the 'plot_grid' function from the cowplot package to put these
# together in a figure.
cowplot::plot_grid(
  plot1,
  plot2,
  plot3,
  labels = c('A', 'B', 'C'),
  label_size = 12)

print("Step 2 complete!")


# Step 2: the essentials -------------------------------------------------------

library(tidyverse)
library(edgeR)
library(matrixStats)
library(cowplot)

sampleLabels <- targets$sample
myDGEList <- edgeR::DGEList(Txi_gene$counts)
log2.cpm <- edgeR::cpm(myDGEList, log = TRUE)
log2.cpm.df <- tibble::as_tibble(log2.cpm, rownames = "geneID")
colnames(log2.cpm.df) <- c("geneID", sampleLabels)
log2.cpm.df.pivot <- tidyr::pivot_longer(
  log2.cpm.df, # dataframe to be pivoted
  cols = HS01:CL13, # column names to be stored as a SINGLE variable
  names_to = "samples", # name of that new variable (column)
  values_to = "expression") # name of new variable (column) storing all the values (data)

plot1 <- ggplot2::ggplot(log2.cpm.df.pivot) +
  ggplot2::aes(x = samples, y = expression, fill = samples) +
  ggplot2::geom_violin(trim = FALSE, show.legend = FALSE) +
  ggplot2::stat_summary(
    fun = "median",
    geom = "point",
    shape = 95,
    size = 10,
    color = "black",
    show.legend = FALSE) +
  ggplot2::labs(
    y = "log2 expression",
    x = "sample",
    title = "Log2 Counts per Million (CPM)",
    subtitle = "unfiltered, non-normalized",
    caption = paste0("produced on ", Sys.time())) +
  ggplot2::theme_bw()

keepers <- rowSums(cpm > 1) >= 5 #user defined
myDGEList.filtered <- myDGEList[keepers,]
dim(myDGEList)
dim(myDGEList.filtered)

log2.cpm.filtered <- edgeR::cpm(myDGEList.filtered, log = TRUE)
log2.cpm.filtered.df <- tibble::as_tibble(
  log2.cpm.filtered,
  rownames = "geneID")
colnames(log2.cpm.filtered.df) <- c("geneID", sampleLabels)
log2.cpm.filtered.df.pivot <- tidyr::pivot_longer(
  log2.cpm.filtered.df, # dataframe to be pivoted
  cols = HS01:CL13, # column names to be stored as a SINGLE variable
  names_to = "samples", # name of that new variable (column)
  values_to = "expression") # name of new variable (column) storing all the values (data)

plot2 <- ggplot2::ggplot(log2.cpm.filtered.df.pivot) +
  ggplot2::aes(x = samples, y = expression, fill = samples) +
  ggplot2::geom_violin(trim = FALSE, show.legend = FALSE) +
  ggplot2::stat_summary(
    fun = "median",
    geom = "point",
    shape = 95,
    size = 10,
    color = "black",
    show.legend = FALSE) +
  ggplot2::labs(
    y = "log2 expression",
    x = "sample",
    title = "Log2 Counts per Million (CPM)",
    subtitle = "filtered, non-normalized",
    caption = paste0("produced on ", Sys.time())) +
  ggplot2::theme_bw()

# Normalize your data
myDGEList.filtered.norm <- edgeR::calcNormFactors(
  myDGEList.filtered,
  method = "TMM")
# use the 'cpm' function from EdgeR to get counts per million from your
# normalized data
log2.cpm.filtered.norm <- edgeR::cpm(myDGEList.filtered.norm, log = TRUE)
log2.cpm.filtered.norm.df <- tibble::as_tibble(
  log2.cpm.filtered.norm,
  rownames = "geneID")
colnames(log2.cpm.filtered.norm.df) <- c("geneID", sampleLabels)
# pivot this NORMALIZED data
log2.cpm.filtered.norm.df.pivot <- tidyr::pivot_longer(
  log2.cpm.filtered.norm.df, # dataframe to be pivoted
  cols = HS01:CL13, # column names to be stored as a SINGLE variable
  names_to = "samples", # name of that new variable (column)
  values_to = "expression") # name of new variable (column) storing all the values (data)

plot3 <- ggplot2::ggplot(log2.cpm.filtered.norm.df.pivot) +
  ggplot2::aes(x = samples, y = expression, fill = samples) +
  ggplot2::geom_violin(trim = FALSE, show.legend = FALSE) +
  ggplot2::stat_summary(
    fun = "median",
    geom = "point",
    shape = 95,
    size = 10,
    color = "black",
    show.legend = FALSE) +
  ggplot2::labs(
    y = "log2 expression",
    x = "sample",
    title = "Log2 Counts per Million (CPM)",
    subtitle = "filtered, TMM normalized",
    caption = paste0("produced on ", Sys.time())) +
  ggplot2::theme_bw()

cowplot::plot_grid(
  plot1,
  plot2,
  plot3,
  labels = c('A', 'B', 'C'),
  label_size = 12)


# Step 3------------------------------------------------------------------------

# This script walks thorough techniques for data exploration and expands on
# last week's data wrangling theme. We'll also continue to create
# publication-quality graphics. This script starts with your filtered and
# normalized abundance data from the Step 2 script.

# Identify variables of interest in study design file
group <- targets$group |> factor()

# Required data:
log2.cpm.filtered.norm.df

# Hierarchical clustering ---------------
# hierarchical clustering can only work on a data matrix, not a data frame.
# try using filtered and unfiltered data...how does this change the result?
# try other distance methods (e.g. switch from 'maximum' to 'euclidean')...
# how does this change the result?

# other distance methods are "euclidean", maximum", "manhattan", "canberra",
# "binary" or "minkowski"
# distance <- dist(t(log2.cpm.filtered.norm), method = "maximum")
distance <- log2.cpm.filtered.norm |> t() |> stats::dist(method = "euclidean")
stats::as.dist(distance)

# other agglomeration methods are "ward.D", "ward.D2", "single", "complete",
# "average", "mcquitty", "median", or "centroid"
clusters <- hclust(distance, method = "complete")
plot(clusters, labels = sampleLabels)

# Principal component analysis (PCA) -------------
pca.res <-
  log2.cpm.filtered.norm |>
  t() |>
  stats::prcomp(scale = FALSE, retx = TRUE)

# Look at the PCA result (pca.res) that you just created
ls(pca.res)
# Prints variance summary for all principal components.
summary(pca.res)
# $rotation shows you how much each gene influenced each PC (called 'scores')
pca.res$rotation
# 'x' shows you how much each sample influenced each PC (called 'loadings')
pca.res$x
# Note that these have a magnitude and a direction (this is the basis
# for making a PCA plot).

# A screeplot is a standard way to view eigenvalues for each PCA
stats::screeplot(pca.res)
# sdev^2 captures these eigenvalues from the PCA result
pc.var <- pca.res$sdev^2
# We can then use these eigenvalues to calculate the percentage variance
# explained by each PC
pc.per <- round(pc.var * 100 / sum(pc.var), 1)
pc.per
# Visualize your PCA result ------------------
# lets first plot any two PCs against each other
# We know how much each sample contributes to each PC (loadings), so let's plot
pca.res.df <- tibble::as_tibble(pca.res$x)
ggplot2::ggplot(pca.res.df) +
  aes(x = PC1, y = PC2, label = sampleLabels, color = group) +
  geom_point(size = 4) +
  geom_label() +
  stat_ellipse() +
  xlab(paste0("PC1 (",pc.per[1], "%", ")")) +
  ylab(paste0("PC2 (",pc.per[2], "%", ")")) +
  labs(
    title = "PCA plot",
    caption = paste0("produced on ", Sys.time())) +
  theme_bw()

# Let's discuss and iteratively refine the PCA code and plot from above
# First, take note of the fact that we can use information from our PCA analysis
# to label our axes.
# Remember that PCA is unsupervised, so knows nothing about group assignment
# (healthy vs disease).
# But *we* know, and so we can use this knowledge to enhance the plot.
# Add a 'color=group' mapping to the aes of the plot above.
# Can we figure out the identity of the outlier?  We have already provided
# samplelabel mapping in aes, so just uncomment the 'geom_label()',
# Uncomment 'coord_fixed()' to apply the correct aspect ratio.
# Uncomment 'stat_ellipse()' to see how you can circle clusters on the PCA.
# How would this PCA look if you used raw counts (myCounts) instead of log2 CPM?
# What are the disadvantages of looking at a PCA result using such a
# simple XY plot?

# Create a PCA 'small multiples' chart ----
# This is another way to view PCA laodings to understand impact of each sample
# on each pricipal component.

# Note that this is the first time you've seen the 'pipe' operator from the
# magrittr package
pca.res.df <- pca.res$x[, 1:4] |>
  as_tibble() |>
  add_column(sample = sampleLabels, group = group)

pca.pivot <- pivot_longer(
  # dataframe to be pivoted
  pca.res.df,
  # column names to be stored as a SINGLE variable
  cols = PC1:PC4,
  # name of that new variable (column)
  names_to = "PC",
  # name of new variable (column) storing all the values (data)
  values_to = "loadings")

ggplot(pca.pivot) +
  # you could iteratively 'paint' different covariates onto this
  # plot using the 'fill' aes
  aes(x = sample, y = loadings, fill = group) +
  geom_bar(stat = "identity") +
  facet_wrap(~PC) +
  labs(
    title = "PCA 'small multiples' plot",
    caption = paste0("produced on ", Sys.time())) +
  theme_bw() +
  coord_flip()

# Use dplyr 'verbs' to modify our dataframe ----
# Use dplyr 'mutate' function to add new columns based on existing data
mydata.df <-
  log2.cpm.filtered.norm.df |>
  dplyr::mutate(
    healthy.AVG = (HS01 + HS02 + HS03 + HS04 + HS05) / 5,
    disease.AVG = (CL08 + CL10 + CL11 + CL12 + CL13) / 5,
    # Now make columns comparing each of the averages above
    # that you're interested in
    LogFC = (disease.AVG - healthy.AVG)) |>
  dplyr::mutate_if(is.numeric, round, 2)

# Now look at this modified data table
mydata.df

# Use dplyr 'arrange' and 'select' to sort your dataframe based on any variable.
# First, we'll use dplyr "arrange" function to sort rows based on the values in
# a column of interest.
# Then we'll display 'select' only the columns we're interested in seeing.
mydata.sort <-
  mydata.df |>
  dplyr::arrange(desc(LogFC)) |>
  dplyr::select(geneID, LogFC)

# Use dplyr "filter" and "select" functions to pick out genes of interest
# ways to tweak the 'select' function:
# use ':' between two column names to select all columns between
# use 'contains', 'starts_with' or 'ends_with' to modify how you select
# can refer to columns using exact name or numerical indicator
# use boolean operators such as '&' (and), '|' (or), '==' (equal to), '!' (not)
mydata.filter <-
  mydata.df |>
  dplyr::filter(
    geneID %in% c(
      "MMP1",
      "GZMB",
      "IL1B",
      "GNLY",
      "IFNG",
      "CCL4",
      "PRF1",
      "APOBEC3A",
      "UNC13A")) |>
  dplyr::select(geneID, healthy.AVG, disease.AVG, LogFC) |>
  dplyr::arrange(dplyr::desc(LogFC))

# you can also filter based on any regular expression
mydata.grep <-
  mydata.df |>
  dplyr::filter(grepl("CXCL|IFI", geneID))|>
  dplyr::select(geneID, healthy.AVG, disease.AVG, LogFC) |>
  dplyr::arrange(dplyr::desc(geneID))

# now with a few more options
mydata.filter |>
  gt::gt() |>
  gt::fmt_number(columns = 2:4, decimals = 1) |>
  gt::tab_header(
    title = gt::md("**Regulators of skin pathogenesis**"),
    subtitle = gt::md("*during cutaneous leishmaniasis*")) |>
  gt::tab_footnote(
    footnote = "Deletion or blockaid ameliorates disease in mice",
    locations = cells_body(
      columns = geneID,
      rows = c(6, 7))) |>
  gt::tab_footnote(
    footnote = "Associated with treatment failure in multiple studies",
    locations = cells_body(
      columns = geneID,
      rows = c(2:9))) |>
  gt::tab_footnote(
    footnote = "Implicated in parasite control",
    locations = cells_body(
      columns = geneID,
      rows = c(2))) |>
  gt::tab_source_note(
    source_note = gt::md(
      "Reference: Amorim *et al*., (2019). DOI: 10.1126/scitranslmed.aar3619"))

# Make an interactive table using the DT package ----
DT::datatable(
  mydata.df[, c(1, 12:14)],
  extensions = c("KeyTable", "FixedHeader"),
  filter = "top",
  options = list(
    keys = TRUE,
    searchHighlight = TRUE,
    pageLength = 10,
    lengthMenu = c("10", "25", "50", "100")))

# Make an interactive scatter plot with plotly -----
# Begin by storing your ggplot object.
myplot <- ggplot2::ggplot(mydata.df) +
  aes(x = healthy.AVG, y = disease.AVG) +
  geom_point(shape = 16, size = 1) +
  ggtitle("disease vs. healthy") +
  theme_bw()
# now use the ggplotly function from the plotly package to convert this
# ggplot object into an interactive plot
plotly::ggplotly(myplot)

# Let's customize this graphic by adding a more informative mouseover tooltip
myplot <- ggplot2::ggplot(mydata.df) +
  aes(x = healthy.AVG, y = disease.AVG, text = geneID) +
  geom_point(shape = 16, size = 1) +
  ggtitle("disease vs. healthy") +
  theme_bw()
plotly::ggplotly(myplot)


# Step 3: the essentials -------------------------------------------------------

library(tidyverse)
library(DT)
library(gt)
library(plotly)

group <- targets$group |> factor()

# Principal component analysis (PCA)
pca.res <-
  log2.cpm.filtered.norm |>
  t() |>
  stats::prcomp(scale = FALSE, retx = TRUE)
# sdev^2 captures these eigenvalues from the PCA result
pc.var <- pca.res$sdev^2
# Percentage variance explained by each PC
pc.per <- round(pc.var * 100 / sum(pc.var), 1)

pca.res.df <- as_tibble(pca.res$x)
# Plot PC1 and PC2 against each other
pca.res.df <- tibble::as_tibble(pca.res$x)
pca.plot <- ggplot2::ggplot(pca.res.df) +
  aes(x = PC1, y = PC2, label = sampleLabels, color = group) +
  geom_point(size = 4) +
  geom_label() +
  stat_ellipse() +
  xlab(paste0("PC1 (",pc.per[1], "%", ")")) +
  ylab(paste0("PC2 (",pc.per[2], "%", ")")) +
  labs(
    title = "PCA plot",
    caption = paste0("produced on ", Sys.time())) +
  theme_bw()
plotly::ggplotly(pca.plot)

mydata.df <- log2.cpm.filtered.norm.df |>
  dplyr::mutate(
    healthy.AVG = (HS01 + HS02 + HS03 + HS04 + HS05) / 5,
    disease.AVG = (CL08 + CL10 + CL11 + CL12 + CL13) / 5,
    LogFC = (disease.AVG - healthy.AVG)) |>
  dplyr::mutate_if(is.numeric, round, 2)

# Make an interactive table
DT::datatable(
  mydata.df[, c(1, 12:14)],
  extensions = c("KeyTable", "FixedHeader"),
  filter = "top",
  options = list(
    keys = TRUE,
    searchHighlight = TRUE,
    pageLength = 20000,
    lengthMenu = c("10", "25", "50", "100")))


# Step 4------------------------------------------------------------------------

# the goal of this script is to identify differentially expressed genes (DEGs)
# and differential transcript usage (DTU)
# you should already know which pairwise comparisons are most important to you
# whether you look for differential expression at the gene or transcript level
# depends on how you read the Kallisto output into R using TxImport
# back in Step 1
# if you have no biological replicates, you will NOT be able to leverage
# statistical tools for differential expression analysis
# instead, you will ONLY rely on fold changes, and can use the dplyr 'verbs'
# we discussed in Step 3 and 4 to identify genes based on log fold-change

# Set up your design matrix ----
design <- model.matrix(~0 + group)
colnames(design) <- levels(group)

# NOTE: if you need a paired analysis (a.k.a.'blocking' design) or have a
# batch effect, the following design is useful:
# design <- model.matrix(~block + treatment)
# this is just an example. 'block' and 'treatment' would need to be objects
# in your environment

# Model mean-variance trend and fit linear model to data ----
# Use VOOM function from Limma package to model the mean-variance relationship
v.DEGList.filtered.norm <- limma::voom(
  myDGEList.filtered.norm,
  design = design,
  plot = TRUE)
# fit a linear model to your data
fit <- limma::lmFit(v.DEGList.filtered.norm, design = design)
# Design matrix and linear model: https://youtu.be/R7xd624pR1A
# Contrast matrix ----
contrast.matrix <- limma::makeContrasts(
  infection = disease - healthy,
  levels = design)

# extract the linear model fit -----
fits <- limma::contrasts.fit(fit, contrast.matrix)
# get bayesian stats for your linear model fit
ebFit <- limma::eBayes(fits)
#write.fit(ebFit, file="lmfit_results.txt")

# TopTable to view DEGs -----

# TopTable (from limma) outputs a few different stats:
# logFC, AveExpr, and P.Value should be self-explanatory
# adj.P.Val is your adjusted P value, also known as an FDR (if BH method was
# used for multiple testing correction)
# B statistic is the log-odds that that gene is differentially expressed.
# If B = 1.5, then log odds is e^1.5, where e is euler's constant
# (approx. 2.718).  So, the odds of differential expression os about 4.8 to 1
# t statistic is ratio of the logFC to the standard error (where the error has
# been moderated across all genes...because of Bayesian approach)

myTopHits <- limma::topTable(
  ebFit,
  adjust.method = "BH",
  coef = 1,
  number = 40000,
  sort.by = "logFC")

# Convert to a tibble
myTopHits.df <- myTopHits |> tibble::as_tibble(rownames = "geneID")

vplot <-
  ggplot2::ggplot(myTopHits.df) +
  ggplot2::aes(x = logFC, y = -log10(adj.P.Val), text = geneID) +
  ggplot2::geom_point(size = 0.2) +
  ggplot2::geom_hline(
    yintercept = -log10(0.01),
    linetype = "longdash",
    colour= "grey",
    linewidth = 1) +
  ggplot2::geom_vline(
    xintercept = 1,
    linetype ="longdash",
    colour = "coral",
    linewidth = 1) +
  ggplot2::geom_vline(
    xintercept = -1,
    linetype = "longdash",
    colour = "cadetblue",
    linewidth = 1) +
  ggplot2::annotate(
    "rect",
    xmin = 1,
    xmax = 12,
    ymin = -log10(0.01),
    ymax = 7.5,
    alpha = .2,
    fill = "coral") +
  ggplot2::annotate(
    "rect",
    xmin = -1,
    xmax = -12,
    ymin = -log10(0.01),
    ymax = 7.5,
    alpha=.2,
    fill = "cadetblue") +
  ggplot2::labs(
    title = "Volcano plot",
    subtitle = "Cutaneous leishmaniasis",
    caption = paste0("produced on ", Sys.time())) +
  ggplot2::theme_bw()

# Now make the volcano plot above interactive with plotly
plotly::ggplotly(vplot)

# decideTests to pull out the DEGs and make Venn Diagram ----
results <- limma::decideTests(
  ebFit,
  method = "global",
  adjust.method = "BH",
  p.value = 0.01,
  lfc = 7)

# take a look at what the results of decideTests looks like
head(results)
summary(results)
limma::vennDiagram(results, include = "both")

# retrieve expression data for your DEGs ----
head(v.DEGList.filtered.norm$E)
colnames(v.DEGList.filtered.norm$E) <- sampleLabels

diffGenes <- v.DEGList.filtered.norm$E[results[, 1] != 0,]
head(diffGenes)
dim(diffGenes)
# convert your DEGs to a dataframe using as_tibble
diffGenes.df <- as_tibble(diffGenes, rownames = "geneID")

# create interactive tables to display your DEGs
DT::datatable(
  diffGenes.df,
  extensions = c("KeyTable", "FixedHeader"),
  caption = "Table 1: DEGs in cutaneous leishmaniasis",
  options = list(
    keys = TRUE,
    searchHighlight = TRUE,
    pageLength = 10000,
    lengthMenu = c("10", "25", "50", "100"))) |>
  DT::formatRound(columns=c(2:11), digits=2)

# write your DEGs to a file
# NOTE: this .txt file can be directly used for input into other clustering
# or network analysis tools
# (e.g., String, Clust (https://github.com/BaselAbujamous/clust, etc.)
readr::write_tsv(diffGenes.df, "DiffGenes.txt")

# Create a heatmap of differentially expressed genes ----
heatmaply::heatmaply(
  diffGenes.df[2:11],
  # dendrogram = "row",
  xlab = "Samples",
  ylab = "DEGs",
  main = "DEGs in cutaneous leishmaniasis",
  scale = "column",
  margins = c(60, 100, 40, 20),
  grid_color = "white",
  grid_width = 0.0000001,
  titleX = TRUE,
  titleY = TRUE,
  hide_colorbar = TRUE,
  branches_lwd = 0.1,
  label_names = c("Gene", "Sample:", "Value"),
  fontsize_row = 5,
  fontsize_col = 5,
  labCol = colnames(diffGenes.df)[2:11],
  labRow = diffGenes.df$geneID,
  heatmap_layers = theme(axis.line = element_blank()))

# OPTIONAL: differential transcript usage (DTU) analysis -----------------------

# # The IsoformSwitchAnalyzeR package looks for certain column headers in our
# # study design
# # So, the first step is to make sure our study design contains the following:
# # unique sample IDs must be contained in column called 'sampleID'
# # covariate(s) of interest must be in column labeled 'condition'
# # remove extraneous columns
# targets.mod <- targets |>
#   dplyr::rename(sampleID = sample, condition = group) |>
#   dplyr::select(sampleID, condition)
#
# # import transcript Kallisto quant data
# # using the same path variable we set way back in the step 1 script
# Txi_trans <- importIsoformExpression(sampleVector = path)
#
# # fix column headers of abundance and counts data to match sampleID in target.mod
# colnames(Txi_trans$abundance) <- c("isoform_id", sampleLabels)
# colnames(Txi_trans$counts) <- c("isoform_id", sampleLabels)
#
# # import data
# mySwitchList <- IsoformSwitchAnalyzeR::importRdata(
#   isoformCountMatrix   = Txi_trans$counts,
#   isoformRepExpression = Txi_trans$abundance,
#   designMatrix         = targets.mod,
#   removeNonConvensionalChr = TRUE,
#   addAnnotatedORFs=TRUE,
#   ignoreAfterPeriod=TRUE,
#   # the files below must be from the same ensembl release
#   # (in this case release 108), and must match the reference release version
#   # that we originally mapped our reads to at the beginning of the course
#   # you can find version 108 of the gtf file below here:
#   # https://ftp.ensembl.org/pub/release-108/gtf/homo_sapiens/
#   isoformExonAnnoation = "Homo_sapiens.GRCh38.108.chr_patch_hapl_scaff.gtf.gz",
#   isoformNtFasta       = "Homo_sapiens.GRCh38.cdna.all.fa",
#   showProgress = TRUE)
#
# # Error in IsoformSwitchAnalyzeR::importRdata(isoformCountMatrix
# # = Txi_trans$counts,  : At least one of the file(s) pointed to with
# # 'isoformNtFasta' seems not to exist.
#
# # We'll do the isoform analysis in one step, but there's a lot to unpack here,
# # so you should really read the package documentation at:
# # https://bioconductor.org/packages/release/bioc/vignettes/
# # IsoformSwitchAnalyzeR/inst/doc/IsoformSwitchAnalyzeR.html
# # Note that without additional manual work here (beyond the scope of this
# # class), we'll only capture isoform annotations for
# # 1) intron retention;
# # 2) ORF sequence similarity; and
# # 3) nonsense mediate decay (NMD)
#
# #NOTE: THIS NEXT BIT COULD TAKE A WHILE!
# mySwitchList <- IsoformSwitchAnalyzeR::isoformSwitchAnalysisCombined(
#   switchAnalyzeRlist   = mySwitchList,
#   pathToOutput = 'isoform_output') # directory must already exist
#
# # now look at the directory that you just created above
# # in case you missed the summary output from the function above
# IsoformSwitchAnalyzeR::extractSwitchSummary(mySwitchList)
#
# # extract the top n isoform switching events
# IsoformSwitchAnalyzeR::extractTopSwitches(
#   mySwitchList,
#   filterForConsequences = TRUE, # these 'consequences' related to the annotations I reference above.
#   n = 50,
#   sortByQvals = FALSE) #change to TRUE if you want this list sorted by FDR-adusted Pval (a.k.a., q value)
#
# # visualize by making a 'switch plot'
# IsoformSwitchAnalyzeR::switchPlot(
#   mySwitchList,
#   gene='FCGR3B',
#   condition1 = 'disease',
#   condition2 = 'healthy',
#   localTheme = theme_bw())

# Step 4: the essentials -------------------------------------------------------

library(tidyverse)
library(limma)
library(edgeR)
library(gt)
library(DT)
library(plotly)

# Set up your design matrix
design <- model.matrix(~0 + group)
colnames(design) <- levels(group)

# Model mean-variance trend and fit linear model to data
# Use VOOM function from Limma package to model the mean-variance relationship
v.DEGList.filtered.norm <- limma::voom(
  myDGEList.filtered.norm,
  design = design)
# Fit a linear model to your data
fit <- limma::lmFit(v.DEGList.filtered.norm, design = design)
# Contrast matrix
contrast.matrix <- limma::makeContrasts(
  infection = disease - healthy,
  levels = design)
# Extract the linear model fit
fits <- limma::contrasts.fit(fit, contrast.matrix)
# Get bayesian stats for your linear model fit
ebFit <- limma::eBayes(fits)
# TopTable to view DEGs
myTopHits <- limma::topTable(
  ebFit,
  adjust.method = "BH",
  coef = 1,
  number = 40000,
  sort.by = "logFC")
myTopHits.df <- myTopHits |> tibble::as_tibble(rownames = "geneID")

vplot <-
  ggplot2::ggplot(myTopHits.df) +
  ggplot2::aes(x = logFC, y = -log10(adj.P.Val), text = geneID) +
  ggplot2::geom_point(size = 0.2) +
  ggplot2::geom_hline(
    yintercept = -log10(0.01),
    linetype = "longdash",
    colour= "grey",
    linewidth = 1) +
  ggplot2::geom_vline(
    xintercept = 1,
    linetype ="longdash",
    colour = "coral",
    linewidth = 1) +
  ggplot2::geom_vline(
    xintercept = -1,
    linetype = "longdash",
    colour = "cadetblue",
    linewidth = 1) +
  ggplot2::annotate(
    "rect",
    xmin = 1,
    xmax = 12,
    ymin = -log10(0.01),
    ymax = 7.5,
    alpha = .2,
    fill = "coral") +
  ggplot2::annotate(
    "rect",
    xmin = -1,
    xmax = -12,
    ymin = -log10(0.01),
    ymax = 7.5,
    alpha=.2,
    fill = "cadetblue") +
  ggplot2::labs(
    title = "Volcano plot",
    subtitle = "Cutaneous leishmaniasis",
    caption = paste0("produced on ", Sys.time())) +
  ggplot2::theme_bw()
# Interactive volcano plot
plotly::ggplotly(vplot)

# Pull out the DEGs and make a Venn Diagram
results <- limma::decideTests(
  ebFit,
  method = "global",
  adjust.method = "BH",
  p.value = 0.01,
  lfc = 7)
limma::vennDiagram(results, include = "both")

colnames(v.DEGList.filtered.norm$E) <- sampleLabels
diffGenes <- v.DEGList.filtered.norm$E[results[, 1] != 0,]
diffGenes.df <- as_tibble(diffGenes, rownames = "geneID")

# Create interactive tables to display your DEGs
DT::datatable(
  diffGenes.df,
  extensions = c("KeyTable", "FixedHeader"),
  caption = "Table 1: DEGs in cutaneous leishmaniasis",
  options = list(
    keys = TRUE,
    searchHighlight = TRUE,
    pageLength = 10000,
    lengthMenu = c("10", "25", "50", "100"))) |>
  DT::formatRound(columns=c(2:11), digits=2)

# Step 5------------------------------------------------------------------------

# For the purposes of this script we'll want several data objects generated in
# previous scripts, including:
# 1) your normalized filtered expression data, in the form of a data matrix
#    with symbols as rownames.
# 2) your study design file
# 3) your contrast matrix that lays out the pairwise comparisons you're
#    interested in testing
# 4) Individual signatures or 'collections' of signatures to test for
#    enrichment in your data.
# These signatures can be downloaded from gene signature databases such
# as MSigDB.
# Signatures can also be custom made based on your interests.
# Signatures can also be pulled from R/Bioconductor as described below


# Carry out GO enrichment using gProfiler2
# Use topTable result to pick the top genes for carrying out a
# Gene Ontology (GO) enrichment analysis.

myTopHits <- limma::topTable(
  ebFit,
  adjust.method = "BH",
  coef = 1,
  number = 50,
  sort.by = "logFC")

# Run GO enrichment analysis
gost.res <- gprofiler2::gost(
  rownames(myTopHits),
  organism = "hsapiens",
  correction_method = "fdr")

# Produce an interactive manhattan plot of enriched GO terms.
# Set 'interactive = FALSE' to get plot for publications.
gprofiler2::gostplot(gost.res, interactive = TRUE, capped = FALSE)
# Produce a publication quality static manhattan plot
# with specific GO terms highlighted.
# Rerun the above gostplot function with 'interactive = FALSE'
# and save to an object 'mygostplot'
mygostplot = gprofiler2::gostplot(gost.res, interactive = FALSE, capped = FALSE)
gprofiler2::publish_gostplot(
  # your static gostplot from above
  mygostplot,
  highlight_terms = c("GO:0034987"),
  filename = NULL,
  width = NA,
  height = NA)

# Generate a table of your gost results
# Does not work on my computer.
# gprofiler2::publish_gosttable(
#   gost.res,
#   highlight_terms = NULL,
#   use_colors = TRUE,
#   show_columns = c("source", "term_name", "term_size", "intersection_size"),
#   filename = NULL,
#   ggplot = TRUE
# )

# now repeat the above steps using only genes from a single module from
# the step 6 script, by using `rownames(myModule)`
# what is value in breaking up DEGs into modules for functional enrichment
# analysis?

# Competitive GSEA using CAMERA

# For competitive tests the null hypothesis is that genes in the set are,
# at most, as often differentially expressed as genes outside the set.
# First let's create a few signatures to test in our enrichment analysis.

# if your own data is from mice, wrap this in 'toupper()'
# to make gene symbols all caps
mySig <- rownames(myTopHits)
mySig2 <- sample(
  (rownames(v.DEGList.filtered.norm$E)),
  size = 50,
  replace = FALSE)
collection <- list(real = mySig, fake = mySig2)

# Test for enrichment using CAMERA
camera.res <- limma::camera(
  v.DEGList.filtered.norm$E,
  collection,
  design,
  contrast.matrix[, 1])
camera.df <- tibble::as_tibble(camera.res, rownames = "setName")
camera.df

# Self-contained GSEA using ROAST
# Remember that for self-contained the null hypothesis is that no genes
# in the set are differentially expressed
# mroast adjusts for multiple testing
limma::mroast(v.DEGList.filtered.norm$E, collection, design, contrast = 1)

# Now repeat with an actual gene set collection
# Camera requires collections to be presented as a list, rather than a tibble,
# so we must read in our signatures using the 'getGmt' function
broadSet.C2.ALL <- GSEABase::getGmt(
  "c2.cp.kegg.v2023.1.Hs.symbols.gmt",
  geneIdType = SymbolIdentifier())
# Option for plants: goto http://structuralbiology.cau.edu.cn/PlantGSEA/download.php
# Download the gene set of interest for the species of interest (e.g. Ara_KEGG.txt)
# broadSet.C2.ALL <- getGmt("Ara_KEGG.txt",geneIdType=SymbolIdentifier())
# broadSet.C2.ALL <- geneIds(broadSet.C2.ALL)

# Extract as a list
broadSet.C2.ALL <- GSEABase::geneIds(broadSet.C2.ALL)
camera.res <- limma::camera(
  v.DEGList.filtered.norm$E,
  broadSet.C2.ALL,
  design,
  contrast.matrix[, 1])
camera.df <- tibble::as_tibble(camera.res, rownames = "setName")
camera.df

# Filter based on FDR and display as interactive table
# FDR(gene) is the probability that a gene, whose p-value is P(gene),
# - adjusted for multiple tests.
# is not differentially expressed, taking into account the whole set of tests.
# FDR stands for false discovery rate. In genetics, FDR 0.05 is common.
camera.df <- filter(camera.df, FDR <= 0.01)

DT::datatable(
  camera.df,
  extensions = c('KeyTable', "FixedHeader"),
  caption = 'Signatures enriched in leishmaniasis',
  options = list(
    keys = TRUE,
    searchHighlight = TRUE,
    pageLength = 10000,
    lengthMenu = c("10", "25", "50", "100")
  )) |>
  DT::formatRound(columns = c(4, 5), digits = 4)

# As before, add a variable that maps up/down regulated pathways with phenotype
camera.df <- camera.df |>
  mutate(phenotype = case_when(
    Direction == "Up" ~ "disease",
    Direction == "Down" ~ "healthy"))

# easy to filter this list based on names of signatures using 'str_detect'
# here is an example of filtering to return anything that has 'CD8' or 'CYTOTOX'
# in the name of the signature
camera.df.sub <-
  camera.df |>
  dplyr::filter(str_detect(setName, "CD8|CYTOTOX"))

# Graph camera results as bubble chart
ggplot2::ggplot(camera.df[1:25,], ggplot2::aes(x = phenotype, y = setName)) +
  ggplot2::geom_point(aes(
    size = NGenes,
    color = Direction,
    alpha = -log10(FDR)
  )) +
  ggplot2::theme_bw()

# Single sample GSEA using the GSVA package
# the GSVA package offers a different way of approaching functional enrichment analysis.
# A few comments about the approach:
# In contrast to most GSE methods, GSVA performs a change in coordinate systems,
# transforming the data from a gene by sample matrix to a gene set (signature)
# by sample matrix.
# This allows for the evaluation of pathway enrichment for each sample.
# The method is both non-parametric and unsupervised.
# bypasses the conventional approach of explicitly modeling phenotypes within
# enrichment scoring algorithms.
# focus is therefore placed on the RELATIVE enrichment of pathways across the
# sample space rather than the absolute enrichment with respect to a phenotype.
# however, with data with a moderate to small sample size (< 30), other GSE
# methods that explicitly include the phenotype in their model are more likely
# to provide greater statistical power to detect functional enrichment.

# be aware that if you choose a large MsigDB file here, this step may take a while
GSVA.res.C2CP <- GSVA::gsva(
  v.DEGList.filtered.norm$E,
  #your data
  broadSet.C2.ALL,
  #signatures
  min.sz = 5,
  max.sz = 500,
  #criteria for filtering gene sets
  mx.diff = FALSE,
  #options for method are "gsva", ssgsea', "zscore" or "plage"
  method = "gsva")

# Apply linear model to GSVA result
# now using Limma to find significantly enriched gene sets in the same way you did to find diffGenes
# this means you'll be using topTable, decideTests, etc
# note that you need to reference your design and contrast matrix here
fit.C2CP <- limma::lmFit(GSVA.res.C2CP, design)
ebFit.C2CP <- limma::eBayes(fit.C2CP)

# use topTable and decideTests functions to identify the differentially enriched gene sets
topPaths.C2CP <-
  topTable(
    ebFit.C2CP,
    adjust = "BH",
    coef = 1,
    number = 50,
    sort.by = "logFC")
res.C2CP <-
  decideTests(
    ebFit.C2CP,
    method = "global",
    adjust.method = "BH",
    p.value = 0.05,
    lfc = 0.58)

# the summary of the decideTests result shows how many sets were enriched in induced and repressed genes in all sample types
summary(res.C2CP)

# pull out the gene sets that are differentially enriched between groups
diffSets.C2CP <- GSVA.res.C2CP[res.C2CP[, 1] !=0, ]
head(diffSets.C2CP)
dim(diffSets.C2CP)

# make a heatmap of differentially enriched gene sets
hr.C2CP <-
  hclust(
    as.dist(1 - cor(t(diffSets.C2CP), method = "pearson")),
    method = "complete") #cluster rows by pearson correlation
hc.C2CP <-
  hclust(
    as.dist(1 - cor(diffSets.C2CP, method = "spearman")),
    method = "complete") #cluster columns by spearman correlation

# Cut the resulting tree and create color vector for clusters.
# Vary the cut height to give more or fewer clusters, or you the 'k' argument
# to force n number of clusters
mycl.C2CP <- stats::cutree(hr.C2CP, k = 2)
mycolhc.C2CP <- grDevices::rainbow(
  length(unique(mycl.C2CP)),
  start = 0.1,
  end = 0.9)
mycolhc.C2CP <- mycolhc.C2CP[as.vector(mycl.C2CP)]

# assign your favorite heatmap color scheme. Some useful examples:
# colorpanel(40, "darkblue", "yellow", "white"); heat.colors(75);
# cm.colors(75); rainbow(75); redgreen(75); library(RColorBrewer);
# rev(brewer.pal(9,"Blues")[-1]). Type demo.col(20) to see more color schemes.
myheatcol <- colorRampPalette(colors = c("yellow", "white", "blue"))(100)

# plot the hclust results as a heatmap
# Creates heatmap for entire data set where the obtained clusters are
# indicated in the color bar.
# just as we did for genes, we can also make an interactive heatmap for pathways
# you can edit what is shown in this heatmap, just as you did for your gene
# level heatmap earlier in the course
gplots::heatmap.2(
  diffSets.C2CP,
  Rowv = as.dendrogram(hr.C2CP),
  Colv = as.dendrogram(hc.C2CP),
  col = myheatcol,
  scale = "row",
  density.info = "none",
  trace = "none",
  cexRow = 0.9,
  cexCol = 1,
  margins = c(10, 14))

# Step 5: the essentials -------------------------------------------------------

library(tidyverse)
library(DT) #interactive and searchable tables of our GSEA results
library(gprofiler2) #tools for accessing the GO enrichment results using g:Profiler web resources
library(clusterProfiler) # provides a suite of tools for functional enrichment analysis
library(msigdbr) # access to msigdb collections directly within R
library(enrichplot) # great for making the standard GSEA enrichment plots

# Run GO enrichment analysis
gost.res <- gprofiler2::gost(
  rownames(myTopHits),
  organism = "hsapiens",
  correction_method = "fdr")

# Produce an interactive manhattan plot of enriched GO terms.
# Set 'interactive = FALSE' to get plot for publications.
gprofiler2::gostplot(gost.res, interactive = TRUE, capped = FALSE)

msigdbr_species()
# NOT AVAILABLE FOR PLANTS
hs_gsea_c2 <-
  msigdbr::msigdbr(
    species = "Homo sapiens", # change depending on species your data came from
    category = "C2") |> # choose your msigdb collection of interest
  #just get the columns corresponding to signature name and gene symbols of genes in each signature
  dplyr::select(gs_name, gene_symbol)

# Now that you have your msigdb collections ready, prepare your data
# grab the dataframe you made in step3 script
# Pull out just the columns corresponding to gene symbols and LogFC
# for at least one pairwise comparison for the enrichment analysis
mydata.df.sub <- dplyr::select(mydata.df, geneID, LogFC)
mydata.gsea <- mydata.df.sub$LogFC
names(mydata.gsea) <- as.character(mydata.df.sub$geneID)
mydata.gsea <- sort(mydata.gsea, decreasing = TRUE)

# run GSEA using the 'GSEA' function from clusterProfiler
myGSEA.res <-
  clusterProfiler::GSEA(mydata.gsea, TERM2GENE = hs_gsea_c2, verbose = FALSE)
myGSEA.df <- as_tibble(myGSEA.res@result)

# View results as an interactive table
DT::datatable(
  myGSEA.df,
  extensions = c('KeyTable', "FixedHeader"),
  caption = 'Signatures enriched in leishmaniasis',
  options = list(
    keys = TRUE,
    searchHighlight = TRUE,
    pageLength = 10000,
    lengthMenu = c("10", "25", "50", "100")
  )) |>
  formatRound(columns = c(3:10), digits = 2)

# Create enrichment plots using the enrichplot package
enrichplot::gseaplot2(
  myGSEA.res,
  geneSetID = 47,
  #can choose multiple signatures to overlay in this plot
  pvalue_table = FALSE,
  #can set this to FALSE for a cleaner plot
  title = myGSEA.res$Description[47]
) #can also turn off this title

# Add a variable to this result that matches enrichment direction with phenotype
myGSEA.df <-
  myGSEA.df |>
  dplyr::mutate(phenotype = case_when(NES > 0 ~ "disease", NES < 0 ~ "healthy"))

# Create 'bubble plot' to summarize y signatures across x phenotypes
ggplot2::ggplot(myGSEA.df[1:20, ], aes(x = phenotype, y = ID)) +
  geom_point(aes(
    size = setSize,
    color = NES,
    alpha = -log10(p.adjust)
  )) +
  scale_color_gradient(low = "blue", high = "red") +
  theme_bw()
